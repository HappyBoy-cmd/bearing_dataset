{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio playback of data\n",
    "This notebook attempts to playback data record from a CPU target to compensate for sensor non-linearity\n",
    "\n",
    "The experiment is structured as follows \n",
    "1. Collect data, arranged based on condition\n",
    "    * OK\n",
    "    * Inner ring damage\n",
    "    * Outer ring damage\n",
    "2. Execute script for \n",
    "    * playing vibration data as audio\n",
    "    * colllecting data from CPU via serial port\n",
    "    * Storing data as waw files\n",
    "    * uploading batch data to edge impulse \n",
    "\n",
    "## Data Sets and Download\n",
    "\n",
    "The main characteristic of the data availible from the Paderborn university are\n",
    "\n",
    "Synchronously measured motor currents and vibration signals with high resolution and sampling rate of __26 damaged bearing states__ and __6 undamaged (healthy) states__ for reference.\n",
    "\n",
    "Supportive measurement of speed, torque, radial load, and temperature.\n",
    "\n",
    "Four different operating conditions (see operating conditions).\n",
    "20 measurements of 4 seconds each for each setting, saved as a MatLab file with a name consisting of the code of the operating condition and the four-digit bearing code (e.g. N15_M07_F10_KA01_1.mat).\n",
    "\n",
    "Systematic description of the bearing damage by uniform fact sheets and a measuring log, which can be downloaded with the data.\n",
    "\n",
    "In total, experiments with 32 different bearing damages in ball bearings of type 6203 were performed:\n",
    "* Undamaged (healthy) bearings (6x), see Table 6 in (pdf).\n",
    "* Artificially damaged bearings (12x), see Table 4 in (pdf).\n",
    "* Bearings with real damages caused by accelerated lifetime tests, (14x) see Table 5 in (pdf)\n",
    "\n",
    "## Dataset description & organisation\n",
    "each experiments data is stored at the universitys homepage, labelled with the __Bearing Code__ (from the table below).__rar__ further below a number of utility finctions for retrieving det data is implemented\n",
    "\n",
    "### Artificial damages\n",
    "The dataset is composed of artificially created and wear based bearing errors.\n",
    "\n",
    "<img src=\"doc/ad.png\" width=\"500\" height=\"250\">\n",
    "\n",
    "The artifiaical damages are manufactured using three different methods:\n",
    "1. electric discharge machining, **EDM** (trench of 0.25 mm length\n",
    "in rolling direction and depth of 1-2 mm),\n",
    "2. drilling (diameter: 0.9 mm, 2 mm, 3 mm), and\n",
    "3. manual electric engraving (damage length from\n",
    "1-4 mm) \n",
    "\n",
    "ISO 15243 gives a methodology for the classification of\n",
    "bearing damage and failures. The damages are categorized\n",
    "into six main damage modes and their sub-modes. The six\n",
    "main damage modes are: fatigue, wear, corrosion, electrical\n",
    "erosion, plastic deformation, and fracture and cracking.\n",
    "\n",
    "**Damage extent for a 6203 bearing**\n",
    "\n",
    "|Damage level | Assigned % value | Limites for 6203 bearing |\n",
    "|--- | --- | --- |\n",
    "| 1 |0-2%|<2mm|\n",
    "| 2 |2-5%|>2mm|\n",
    "| 3 |5-15%|>4.5mm| \n",
    "| 4 |15-35%|>13.5mm|\n",
    "| 5 |>35%|>31.5mm|\n",
    "\n",
    "## Dataset summary \n",
    "In the tavles below a summary of the availble dataset are summarised\n",
    "\n",
    "The availible datasets contains following subsets of data, availivble for download, by the name provided in the initial column\n",
    "\n",
    "### Healthy bearings\n",
    "|Bearing Code | Run-in Period [h] | Radial Load [N] | Speed ​​[min ^ -1] |\n",
    "|--- | --- | --- | --- |\n",
    "| K001 |> 50 | 1000-3000 | 1500-2000 |\n",
    "| K002 | 19 | 3000 | 2900 |\n",
    "| K003 | 1 | 3000 | 3000 | \n",
    "| K004 | 5 | 3000 | 3000 | |\n",
    "| K005 | 10 | 3000 | 3000 | |\n",
    "| K006 | 16 | 3000 | 2900 | |\n",
    "\n",
    "### Bearings with outer ring damage\n",
    "|Bearing Code | Radial Load [N] | Speed ​​[min ^ -1] | Damage method | Damage extent (level) | Damage type |\n",
    "|--- | --- | --- | --- | --- | --- |\n",
    "| KA01 | - | - | EDM |1||\n",
    "| KA03 | - | - | Elec. Engraved|2||\n",
    "| KA04 | - | - | HALT|1|Fatigue,pitting|\n",
    "| KA05 | - | - | Elec. Engraved|1|\n",
    "| KA06 | - | - | Elec. Engraved|2|\n",
    "| KA07 | - | - | Drilling |1|\n",
    "| KA08 | - | - | Drilling |2|\n",
    "| KA09 | - | - | Drilling |2|\n",
    "| KA15 | - |-|HALT|1|Plastic deform.:Indentations|\n",
    "| KA16 | - |-|HALT|2|fatigue: pitting|\n",
    "| KA22 | - |-|HALT|1|fatigue: pitting|\n",
    "| KA30 | - |-|HALT|1|Plastic deform.:Indentations|\n",
    "\n",
    "### Bearings with inner ring damage\n",
    "|Bearing Code | Radial Load [N] | Speed ​​[min ^ -1] | Damage method | Damage extent (level) | Damage type |\n",
    "|--- | --- | --- | --- | --- | --- |\n",
    "| KI01 | - | - |  EDM |1|\n",
    "| KI03 | - | - | Elec. Engraved|1|\n",
    "| KI04 | - | - | HALT |1|Fatigue,pitting|\n",
    "| KI05 | - | - | Elec. Engraved|1|\n",
    "| KI07 | - | - |  Elec. Engraved|2|\n",
    "| KI08 | - | - |  Elec. Engraved|2|\n",
    "| KI14 | - | - | HALT |1|Fatigue,pitting |\n",
    "| KI16 | - | - | HALT |3|Fatigue,pitting |\n",
    "| KI17 | - | - | HALT |1|Fatigue,pitting |\n",
    "| KI18 | - | - | HALT |2|Fatigue,pitting |\n",
    "| KI21 | - | - | HALT |1|Fatigue,pitting |\n",
    "\n",
    "### Bearings with combined inner and outer ring damage\n",
    "|Bearing Code | Radial Load [N] | Speed ​​[min ^ -1] | Damage method | Damage extent (level) |Damage type |\n",
    "|--- | --- | --- | --- | --- | --- |\n",
    "| KB23 | - | - | HALT |2|fatigue: pitting|\n",
    "| KB24 | - | - | HALT |3|fatigue: pitting|\n",
    "| KB27 | - | - | HALT |1|Plastic deform.:Indentations|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import errno\n",
    "import random\n",
    "#import urllib\n",
    "import urllib.request as ug\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import patoolib as pa\n",
    "\n",
    "rarpath = \"/usr/local/bin/unrar\"\n",
    "\n",
    "class PDB:\n",
    "    def __init__(self, exp, rpm, rad_force, torque_mNm, length):\n",
    "        #    def __init__(self):\n",
    "        if exp not in ('K001', 'K002', 'K003', 'K004', 'K005', 'K006','KA01','KA02','KA03','KA04','KA05','KA06'\n",
    "                       ,'KA07','KA08','KA09','KA15','KA16','KA22','KA30','KB23','KB24','KB27','KI01','KI03','KI04'\n",
    "                       ,'KI05','KI07','KI08','KI14','KI16','KI17','KI18','KI21'):\n",
    "            print(\"wrong experiment name: {}\".format(exp))\n",
    "            exit(1)\n",
    "        if rpm not in ('1500', '900'):\n",
    "            print(\"wrong rpm value: {}\".format(rpm))\n",
    "            exit(1)\n",
    "        if rad_force not in ('1000', '400'):\n",
    "            print(\"wrong load value: {}\".format(rad_force))\n",
    "            exit(1)\n",
    "        if torque_mNm not in ('100', '700'):\n",
    "            print(\"wrong torque value: {}\".format(torque_mNm))\n",
    "            exit(1)\n",
    "\n",
    "        dict_rpm = {'1500': 'N15_', '900': 'N09_', '2900': 'N29_'}\n",
    "        dict_torq = {'100': 'M01_', '700': 'M07_'}\n",
    "        dict_load = {'400': 'F04_', '1000': 'F10_'}\n",
    "        #Labels 1 = healthy bearing, 2 = outer ring damage , 3 = inner ring damage, 4 = combined damage\n",
    "        dict_labels = {'K0': 1, 'KA': 2, 'KI': 3, 'KB': 4}\n",
    "\n",
    "        #print(exp[0:2])\n",
    "        self.y_label = dict_labels[exp[0:2]]\n",
    "        print(\"Y is:\")\n",
    "        print(self.y_label)\n",
    "\n",
    "        filestring = dict_rpm[rpm] + dict_torq[torque_mNm] + dict_load[rad_force]\n",
    "        print('filestring')\n",
    "        print(filestring)\n",
    "\n",
    "        # create reciveing dir names from arguments\n",
    "        rdir = os.path.join('.', 'data/PDB', exp)  # ,rpm,load)\n",
    "        fmeta = os.path.join(os.path.dirname('.'), 'metadata.txt')\n",
    "        all_lines = open(fmeta).readlines()\n",
    "\n",
    "        lines = []\n",
    "        for line in all_lines:\n",
    "            l = line.split()\n",
    "            # print(l)\n",
    "            if (l[0] == exp): # and l[1] == rpm and l[2] == rad_force:  # and l[3] == torque_mNm:\n",
    "                lines.append(l)\n",
    "\n",
    "        print(\"l: \")\n",
    "        print(lines)\n",
    "        # prepare download\n",
    "        self.length = length  # sequence length\n",
    "        #        self._load_and_slice_data2(rdir, lines)\n",
    "        self._load_and_slice_data(rdir, lines, filestring)\n",
    "\n",
    "        # shuffle training and test arrays\n",
    "        shuffle = 0\n",
    "        if(shuffle):\n",
    "            self._shuffle()\n",
    "\n",
    "    def _mkdir(self, path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError as exc:\n",
    "            if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "                pass\n",
    "            else:\n",
    "                print(\"can't create directory '{}''\".format(path))\n",
    "                exit(1)\n",
    "\n",
    "    def _download(self, fpath, link):\n",
    "        print(\"Downloading to: '{}'\".format(fpath))\n",
    "        #urllib.request.urlretrieve(link, fpath)\n",
    "        ug.urlretrieve(link, fpath)\n",
    "\n",
    "    def _load_and_slice_data(self, rdir, infos, filestring):\n",
    "\n",
    "        self.X_train = np.zeros((0, self.length))\n",
    "        self.X_test = np.zeros((0, self.length))\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "\n",
    "        ## w\n",
    "        for idx, info in enumerate(infos):\n",
    "\n",
    "            # directory to put the raw rar file\n",
    "            rawdir = os.path.join(rdir, 'raw')\n",
    "            self._mkdir(rawdir)\n",
    "\n",
    "            # path to find the file\n",
    "            fpath = os.path.join(rawdir, info[0] + '.rar')\n",
    "\n",
    "            # if file already exists, avoid duplicate downloads\n",
    "            if not os.path.exists(fpath):\n",
    "                print(\"no dir/file\")\n",
    "                self._download(fpath, info[3].rstrip('\\n'))\n",
    "\n",
    "            # compressed file to uncompress\n",
    "            cmpfile = rawdir + '/' + info[0] + '.rar'\n",
    "\n",
    "            print(\"file to exrtract is is::\")\n",
    "            print(cmpfile)\n",
    "\n",
    "            # unpack file\n",
    "            if not os.path.exists(rdir + '/' + info[0]):\n",
    "                pa.extract_archive(cmpfile, outdir=rdir, program=rarpath)\n",
    "            else:\n",
    "                print(\"file already extracted, skipping unrar\")\n",
    "\n",
    "            # a list of all files in the extracted dir\n",
    "            ddir = rdir + '/' + info[0]\n",
    "            flist_all = os.listdir(ddir)\n",
    "\n",
    "            # print(\"filelist:\")\n",
    "            # print(flist_all)\n",
    "\n",
    "            # use the searchstring, build from the program arguments to find files of interest\n",
    "            flistsorted = [i for i in flist_all if filestring in i]\n",
    "\n",
    "            print(\"sorted filelist:\")\n",
    "            print(flistsorted)\n",
    "\n",
    "            # now build the dataset from all files of interest\n",
    "            # iterate through the filelist\n",
    "            for f in flistsorted:\n",
    "                # load matlab file\n",
    "                mat_dict = loadmat(ddir + '/' + f)#,struct_as_record=False)\n",
    "\n",
    "                # get the values key, tha name of thenactual dataset equal to filename\n",
    "                #key = list(filter(lambda x: 'N15_M07_F04_' in x, mat_dict.keys()))\n",
    "                key = list(filter(lambda x: filestring in x, mat_dict.keys()))\n",
    "                # load data\n",
    "                #time_series = mat_dict[key[0]][:, 0] #['Y']\n",
    "                time_series = mat_dict[key[0]]['Y'][0, 0][0, 6][2][:][0]\n",
    "\n",
    "                idx_last = -(time_series.shape[0] % self.length)\n",
    "                clips = time_series[:idx_last].reshape(-1, self.length)\n",
    "\n",
    "                n = clips.shape[0]\n",
    "\n",
    "                split = 0\n",
    "                if(split):\n",
    "                    # 75% train 25%test\n",
    "                    n_split = int(3 * n / 4)\n",
    "\n",
    "                    self.X_train = np.vstack((self.X_train, clips[:n_split]))\n",
    "                    self.X_test = np.vstack((self.X_test, clips[n_split:]))\n",
    "                    # todo add meaning full label\n",
    "\n",
    "                    self.y_train += [self.y_label] * n_split\n",
    "                    self.y_test  += [self.y_label] * (clips.shape[0] - n_split)\n",
    "\n",
    "                else:\n",
    "                    self.X_train = np.vstack((self.X_train, clips[:n]))\n",
    "                    #self.X_test = np.vstack((self.X_test, clips[n_split:]))\n",
    "                    # todo add meaning full label\n",
    "\n",
    "                    self.y_train += [self.y_label] * n#_split\n",
    "                    #self.y_test  += [self.y_label] * (clips.shape[0] - n_split)\n",
    "                    \n",
    "    def _shuffle(self):\n",
    "        # shuffle training samples\n",
    "        index = list(range(self.X_train.shape[0]))\n",
    "        random.Random(0).shuffle(index)\n",
    "        self.X_train = self.X_train[index]\n",
    "        self.y_train = tuple(self.y_train[i] for i in index)\n",
    "\n",
    "        # shuffle test samples\n",
    "        index = list(range(self.X_test.shape[0]))\n",
    "        random.Random(0).shuffle(index)\n",
    "        self.X_test = self.X_test[index]\n",
    "        self.y_test = tuple(self.y_test[i] for i in index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build list of datasets\n",
    "Each snippet is app 3 seconds, to allow CPU to start sampling\n",
    "\n",
    "'''\n",
    "## Analysis and dataset planning\n",
    "After implementation of analysis and feature extraction functions, the artificial and real datasets are organised and tested as follows\n",
    "\n",
    "|Class||Training|Testing|\n",
    "--- |--- |--- |--- |\n",
    "|1|Healthy|K002|K001|\n",
    "|2|OR damage||KA22|\n",
    "|2|OR damage|KA01|K004|\n",
    "|2|OR damage|KA05|KA15|\n",
    "|2|OR damage|KA07|KA30|\n",
    "|2|OR damage||KA16|\n",
    "|3|IR damage||KI14|\n",
    "|3|IR damage|KI01|KI21|\n",
    "|3|IR damage|KI05|KI17|\n",
    "|3|IR damage|KI07|KI18|\n",
    "|3|IR damage||K16|\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y is:\n",
      "1\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['K001', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/K001.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/K001/raw/K001.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_K001_20.mat', 'N15_M07_F10_K001_19.mat', 'N15_M07_F10_K001_9.mat', 'N15_M07_F10_K001_8.mat', 'N15_M07_F10_K001_18.mat', 'N15_M07_F10_K001_15.mat', 'N15_M07_F10_K001_5.mat', 'N15_M07_F10_K001_4.mat', 'N15_M07_F10_K001_14.mat', 'N15_M07_F10_K001_16.mat', 'N15_M07_F10_K001_6.mat', 'N15_M07_F10_K001_7.mat', 'N15_M07_F10_K001_17.mat', 'N15_M07_F10_K001_3.mat', 'N15_M07_F10_K001_13.mat', 'N15_M07_F10_K001_12.mat', 'N15_M07_F10_K001_2.mat', 'N15_M07_F10_K001_10.mat', 'N15_M07_F10_K001_11.mat', 'N15_M07_F10_K001_1.mat']\n",
      "Y is:\n",
      "1\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['K002', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/K002.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/K002/raw/K002.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_K002_12.mat', 'N15_M07_F10_K002_13.mat', 'N15_M07_F10_K002_11.mat', 'N15_M07_F10_K002_10.mat', 'N15_M07_F10_K002_14.mat', 'N15_M07_F10_K002_15.mat', 'N15_M07_F10_K002_17.mat', 'N15_M07_F10_K002_8.mat', 'N15_M07_F10_K002_9.mat', 'N15_M07_F10_K002_16.mat', 'N15_M07_F10_K002_4.mat', 'N15_M07_F10_K002_5.mat', 'N15_M07_F10_K002_18.mat', 'N15_M07_F10_K002_7.mat', 'N15_M07_F10_K002_6.mat', 'N15_M07_F10_K002_19.mat', 'N15_M07_F10_K002_2.mat', 'N15_M07_F10_K002_3.mat', 'N15_M07_F10_K002_20.mat', 'N15_M07_F10_K002_1.mat']\n",
      "Y is:\n",
      "1\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['K003', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/K003.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/K003/raw/K003.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_K003_19.mat', 'N15_M07_F10_K003_18.mat', 'N15_M07_F10_K003_8.mat', 'N15_M07_F10_K003_9.mat', 'N15_M07_F10_K003_20.mat', 'N15_M07_F10_K003_7.mat', 'N15_M07_F10_K003_10.mat', 'N15_M07_F10_K003_11.mat', 'N15_M07_F10_K003_6.mat', 'N15_M07_F10_K003_4.mat', 'N15_M07_F10_K003_13.mat', 'N15_M07_F10_K003_12.mat', 'N15_M07_F10_K003_5.mat', 'N15_M07_F10_K003_1.mat', 'N15_M07_F10_K003_16.mat', 'N15_M07_F10_K003_17.mat', 'N15_M07_F10_K003_2.mat', 'N15_M07_F10_K003_15.mat', 'N15_M07_F10_K003_14.mat', 'N15_M07_F10_K003_3.mat']\n",
      "Y is:\n",
      "1\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['K004', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/K004.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/K004/raw/K004.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_K004_8.mat', 'N15_M07_F10_K004_9.mat', 'N15_M07_F10_K004_10.mat', 'N15_M07_F10_K004_11.mat', 'N15_M07_F10_K004_13.mat', 'N15_M07_F10_K004_12.mat', 'N15_M07_F10_K004_16.mat', 'N15_M07_F10_K004_17.mat', 'N15_M07_F10_K004_15.mat', 'N15_M07_F10_K004_14.mat', 'N15_M07_F10_K004_19.mat', 'N15_M07_F10_K004_18.mat', 'N15_M07_F10_K004_20.mat', 'N15_M07_F10_K004_2.mat', 'N15_M07_F10_K004_3.mat', 'N15_M07_F10_K004_1.mat', 'N15_M07_F10_K004_4.mat', 'N15_M07_F10_K004_5.mat', 'N15_M07_F10_K004_7.mat', 'N15_M07_F10_K004_6.mat']\n",
      "Y is:\n",
      "1\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['K005', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/K005.rar'], ['K005', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/K006.rar']]\n",
      "no dir/file\n",
      "Downloading to: './data/PDB/K005/raw/K005.rar'\n",
      "file to exrtract is is::\n",
      "./data/PDB/K005/raw/K005.rar\n",
      "patool: Extracting ./data/PDB/K005/raw/K005.rar ...\n",
      "patool: running /usr/local/bin/unrar x -- /Users/opprud/workspace/ceramicspeed/bearingbrain/tools/dataset_for_test/external_data/4_paderborn/data/PDB/K005/raw/K005.rar\n",
      "patool:     with cwd='./data/PDB/K005'\n",
      "patool: ... ./data/PDB/K005/raw/K005.rar extracted to `./data/PDB/K005'.\n",
      "sorted filelist:\n",
      "['N15_M07_F10_K005_18.mat', 'N15_M07_F10_K005_19.mat', 'N15_M07_F10_K005_20.mat', 'N15_M07_F10_K005_8.mat', 'N15_M07_F10_K005_9.mat', 'N15_M07_F10_K005_1.mat', 'N15_M07_F10_K005_2.mat', 'N15_M07_F10_K005_3.mat', 'N15_M07_F10_K005_7.mat', 'N15_M07_F10_K005_6.mat', 'N15_M07_F10_K005_4.mat', 'N15_M07_F10_K005_5.mat', 'N15_M07_F10_K005_12.mat', 'N15_M07_F10_K005_13.mat', 'N15_M07_F10_K005_11.mat', 'N15_M07_F10_K005_10.mat', 'N15_M07_F10_K005_14.mat', 'N15_M07_F10_K005_15.mat', 'N15_M07_F10_K005_17.mat', 'N15_M07_F10_K005_16.mat']\n",
      "file to exrtract is is::\n",
      "./data/PDB/K005/raw/K005.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_K005_18.mat', 'N15_M07_F10_K005_19.mat', 'N15_M07_F10_K005_20.mat', 'N15_M07_F10_K005_8.mat', 'N15_M07_F10_K005_9.mat', 'N15_M07_F10_K005_1.mat', 'N15_M07_F10_K005_2.mat', 'N15_M07_F10_K005_3.mat', 'N15_M07_F10_K005_7.mat', 'N15_M07_F10_K005_6.mat', 'N15_M07_F10_K005_4.mat', 'N15_M07_F10_K005_5.mat', 'N15_M07_F10_K005_12.mat', 'N15_M07_F10_K005_13.mat', 'N15_M07_F10_K005_11.mat', 'N15_M07_F10_K005_10.mat', 'N15_M07_F10_K005_14.mat', 'N15_M07_F10_K005_15.mat', 'N15_M07_F10_K005_17.mat', 'N15_M07_F10_K005_16.mat']\n",
      "Y is:\n",
      "1\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[]\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA01', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA01.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA01/raw/KA01.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA01_8.mat', 'N15_M07_F10_KA01_17.mat', 'N15_M07_F10_KA01_16.mat', 'N15_M07_F10_KA01_9.mat', 'N15_M07_F10_KA01_14.mat', 'N15_M07_F10_KA01_15.mat', 'N15_M07_F10_KA01_11.mat', 'N15_M07_F10_KA01_10.mat', 'N15_M07_F10_KA01_12.mat', 'N15_M07_F10_KA01_13.mat', 'N15_M07_F10_KA01_1.mat', 'N15_M07_F10_KA01_2.mat', 'N15_M07_F10_KA01_20.mat', 'N15_M07_F10_KA01_3.mat', 'N15_M07_F10_KA01_7.mat', 'N15_M07_F10_KA01_18.mat', 'N15_M07_F10_KA01_19.mat', 'N15_M07_F10_KA01_6.mat', 'N15_M07_F10_KA01_4.mat', 'N15_M07_F10_KA01_5.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA03', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA03.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA03/raw/KA03.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA03_12.mat', 'N15_M07_F10_KA03_13.mat', 'N15_M07_F10_KA03_11.mat', 'N15_M07_F10_KA03_9.mat', 'N15_M07_F10_KA03_8.mat', 'N15_M07_F10_KA03_10.mat', 'N15_M07_F10_KA03_14.mat', 'N15_M07_F10_KA03_15.mat', 'N15_M07_F10_KA03_17.mat', 'N15_M07_F10_KA03_16.mat', 'N15_M07_F10_KA03_3.mat', 'N15_M07_F10_KA03_2.mat', 'N15_M07_F10_KA03_18.mat', 'N15_M07_F10_KA03_1.mat', 'N15_M07_F10_KA03_19.mat', 'N15_M07_F10_KA03_5.mat', 'N15_M07_F10_KA03_4.mat', 'N15_M07_F10_KA03_20.mat', 'N15_M07_F10_KA03_6.mat', 'N15_M07_F10_KA03_7.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA04', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA04.rar']]\n",
      "no dir/file\n",
      "Downloading to: './data/PDB/KA04/raw/KA04.rar'\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA04/raw/KA04.rar\n",
      "patool: Extracting ./data/PDB/KA04/raw/KA04.rar ...\n",
      "patool: running /usr/local/bin/unrar x -- /Users/opprud/workspace/ceramicspeed/bearingbrain/tools/dataset_for_test/external_data/4_paderborn/data/PDB/KA04/raw/KA04.rar\n",
      "patool:     with cwd='./data/PDB/KA04'\n",
      "patool: ... ./data/PDB/KA04/raw/KA04.rar extracted to `./data/PDB/KA04'.\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA04_9.mat', 'N15_M07_F10_KA04_8.mat', 'N15_M07_F10_KA04_18.mat', 'N15_M07_F10_KA04_19.mat', 'N15_M07_F10_KA04_20.mat', 'N15_M07_F10_KA04_12.mat', 'N15_M07_F10_KA04_13.mat', 'N15_M07_F10_KA04_11.mat', 'N15_M07_F10_KA04_10.mat', 'N15_M07_F10_KA04_14.mat', 'N15_M07_F10_KA04_15.mat', 'N15_M07_F10_KA04_17.mat', 'N15_M07_F10_KA04_16.mat', 'N15_M07_F10_KA04_6.mat', 'N15_M07_F10_KA04_7.mat', 'N15_M07_F10_KA04_5.mat', 'N15_M07_F10_KA04_4.mat', 'N15_M07_F10_KA04_1.mat', 'N15_M07_F10_KA04_3.mat', 'N15_M07_F10_KA04_2.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA05', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA05.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA05/raw/KA05.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA05_10.mat', 'N15_M07_F10_KA05_11.mat', 'N15_M07_F10_KA05_13.mat', 'N15_M07_F10_KA05_12.mat', 'N15_M07_F10_KA05_16.mat', 'N15_M07_F10_KA05_17.mat', 'N15_M07_F10_KA05_15.mat', 'N15_M07_F10_KA05_14.mat', 'N15_M07_F10_KA05_9.mat', 'N15_M07_F10_KA05_8.mat', 'N15_M07_F10_KA05_5.mat', 'N15_M07_F10_KA05_4.mat', 'N15_M07_F10_KA05_6.mat', 'N15_M07_F10_KA05_7.mat', 'N15_M07_F10_KA05_3.mat', 'N15_M07_F10_KA05_2.mat', 'N15_M07_F10_KA05_1.mat', 'N15_M07_F10_KA05_19.mat', 'N15_M07_F10_KA05_18.mat', 'N15_M07_F10_KA05_20.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA06', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA06.rar']]\n",
      "no dir/file\n",
      "Downloading to: './data/PDB/KA06/raw/KA06.rar'\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA06/raw/KA06.rar\n",
      "patool: Extracting ./data/PDB/KA06/raw/KA06.rar ...\n",
      "patool: running /usr/local/bin/unrar x -- /Users/opprud/workspace/ceramicspeed/bearingbrain/tools/dataset_for_test/external_data/4_paderborn/data/PDB/KA06/raw/KA06.rar\n",
      "patool:     with cwd='./data/PDB/KA06'\n",
      "patool: ... ./data/PDB/KA06/raw/KA06.rar extracted to `./data/PDB/KA06'.\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA06_8.mat', 'N15_M07_F10_KA06_9.mat', 'N15_M07_F10_KA06_20.mat', 'N15_M07_F10_KA06_18.mat', 'N15_M07_F10_KA06_19.mat', 'N15_M07_F10_KA06_17.mat', 'N15_M07_F10_KA06_16.mat', 'N15_M07_F10_KA06_14.mat', 'N15_M07_F10_KA06_15.mat', 'N15_M07_F10_KA06_11.mat', 'N15_M07_F10_KA06_10.mat', 'N15_M07_F10_KA06_12.mat', 'N15_M07_F10_KA06_13.mat', 'N15_M07_F10_KA06_4.mat', 'N15_M07_F10_KA06_5.mat', 'N15_M07_F10_KA06_7.mat', 'N15_M07_F10_KA06_6.mat', 'N15_M07_F10_KA06_2.mat', 'N15_M07_F10_KA06_3.mat', 'N15_M07_F10_KA06_1.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA07', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA07.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA07/raw/KA07.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA07_15.mat', 'N15_M07_F10_KA07_14.mat', 'N15_M07_F10_KA07_16.mat', 'N15_M07_F10_KA07_17.mat', 'N15_M07_F10_KA07_13.mat', 'N15_M07_F10_KA07_12.mat', 'N15_M07_F10_KA07_10.mat', 'N15_M07_F10_KA07_11.mat', 'N15_M07_F10_KA07_8.mat', 'N15_M07_F10_KA07_9.mat', 'N15_M07_F10_KA07_7.mat', 'N15_M07_F10_KA07_6.mat', 'N15_M07_F10_KA07_4.mat', 'N15_M07_F10_KA07_5.mat', 'N15_M07_F10_KA07_1.mat', 'N15_M07_F10_KA07_2.mat', 'N15_M07_F10_KA07_3.mat', 'N15_M07_F10_KA07_20.mat', 'N15_M07_F10_KA07_19.mat', 'N15_M07_F10_KA07_18.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA08', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA08.rar']]\n",
      "no dir/file\n",
      "Downloading to: './data/PDB/KA08/raw/KA08.rar'\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA08/raw/KA08.rar\n",
      "patool: Extracting ./data/PDB/KA08/raw/KA08.rar ...\n",
      "patool: running /usr/local/bin/unrar x -- /Users/opprud/workspace/ceramicspeed/bearingbrain/tools/dataset_for_test/external_data/4_paderborn/data/PDB/KA08/raw/KA08.rar\n",
      "patool:     with cwd='./data/PDB/KA08'\n",
      "patool: ... ./data/PDB/KA08/raw/KA08.rar extracted to `./data/PDB/KA08'.\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA08_2.mat', 'N15_M07_F10_KA08_3.mat', 'N15_M07_F10_KA08_1.mat', 'N15_M07_F10_KA08_4.mat', 'N15_M07_F10_KA08_5.mat', 'N15_M07_F10_KA08_7.mat', 'N15_M07_F10_KA08_6.mat', 'N15_M07_F10_KA08_18.mat', 'N15_M07_F10_KA08_19.mat', 'N15_M07_F10_KA08_20.mat', 'N15_M07_F10_KA08_12.mat', 'N15_M07_F10_KA08_13.mat', 'N15_M07_F10_KA08_11.mat', 'N15_M07_F10_KA08_10.mat', 'N15_M07_F10_KA08_14.mat', 'N15_M07_F10_KA08_15.mat', 'N15_M07_F10_KA08_17.mat', 'N15_M07_F10_KA08_16.mat', 'N15_M07_F10_KA08_8.mat', 'N15_M07_F10_KA08_9.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA09', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA09.rar']]\n",
      "no dir/file\n",
      "Downloading to: './data/PDB/KA09/raw/KA09.rar'\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA09/raw/KA09.rar\n",
      "patool: Extracting ./data/PDB/KA09/raw/KA09.rar ...\n",
      "patool: running /usr/local/bin/unrar x -- /Users/opprud/workspace/ceramicspeed/bearingbrain/tools/dataset_for_test/external_data/4_paderborn/data/PDB/KA09/raw/KA09.rar\n",
      "patool:     with cwd='./data/PDB/KA09'\n",
      "patool: ... ./data/PDB/KA09/raw/KA09.rar extracted to `./data/PDB/KA09'.\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA09_10.mat', 'N15_M07_F10_KA09_11.mat', 'N15_M07_F10_KA09_13.mat', 'N15_M07_F10_KA09_12.mat', 'N15_M07_F10_KA09_16.mat', 'N15_M07_F10_KA09_17.mat', 'N15_M07_F10_KA09_15.mat', 'N15_M07_F10_KA09_14.mat', 'N15_M07_F10_KA09_1.mat', 'N15_M07_F10_KA09_2.mat', 'N15_M07_F10_KA09_3.mat', 'N15_M07_F10_KA09_7.mat', 'N15_M07_F10_KA09_6.mat', 'N15_M07_F10_KA09_4.mat', 'N15_M07_F10_KA09_5.mat', 'N15_M07_F10_KA09_8.mat', 'N15_M07_F10_KA09_9.mat', 'N15_M07_F10_KA09_19.mat', 'N15_M07_F10_KA09_18.mat', 'N15_M07_F10_KA09_20.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA15', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA15.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA15/raw/KA15.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA15_7.mat', 'N15_M07_F10_KA15_15.mat', 'N15_M07_F10_KA15_14.mat', 'N15_M07_F10_KA15_6.mat', 'N15_M07_F10_KA15_4.mat', 'N15_M07_F10_KA15_16.mat', 'N15_M07_F10_KA15_17.mat', 'N15_M07_F10_KA15_5.mat', 'N15_M07_F10_KA15_1.mat', 'N15_M07_F10_KA15_13.mat', 'N15_M07_F10_KA15_12.mat', 'N15_M07_F10_KA15_2.mat', 'N15_M07_F10_KA15_10.mat', 'N15_M07_F10_KA15_11.mat', 'N15_M07_F10_KA15_3.mat', 'N15_M07_F10_KA15_20.mat', 'N15_M07_F10_KA15_8.mat', 'N15_M07_F10_KA15_9.mat', 'N15_M07_F10_KA15_19.mat', 'N15_M07_F10_KA15_18.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA16', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA16.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA16/raw/KA16.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA16_6.mat', 'N15_M07_F10_KA16_7.mat', 'N15_M07_F10_KA16_18.mat', 'N15_M07_F10_KA16_5.mat', 'N15_M07_F10_KA16_4.mat', 'N15_M07_F10_KA16_19.mat', 'N15_M07_F10_KA16_1.mat', 'N15_M07_F10_KA16_20.mat', 'N15_M07_F10_KA16_3.mat', 'N15_M07_F10_KA16_2.mat', 'N15_M07_F10_KA16_12.mat', 'N15_M07_F10_KA16_13.mat', 'N15_M07_F10_KA16_11.mat', 'N15_M07_F10_KA16_10.mat', 'N15_M07_F10_KA16_14.mat', 'N15_M07_F10_KA16_9.mat', 'N15_M07_F10_KA16_8.mat', 'N15_M07_F10_KA16_15.mat', 'N15_M07_F10_KA16_17.mat', 'N15_M07_F10_KA16_16.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA22', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA22.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA22/raw/KA22.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA22_9.mat', 'N15_M07_F10_KA22_8.mat', 'N15_M07_F10_KA22_20.mat', 'N15_M07_F10_KA22_19.mat', 'N15_M07_F10_KA22_18.mat', 'N15_M07_F10_KA22_16.mat', 'N15_M07_F10_KA22_17.mat', 'N15_M07_F10_KA22_15.mat', 'N15_M07_F10_KA22_14.mat', 'N15_M07_F10_KA22_10.mat', 'N15_M07_F10_KA22_11.mat', 'N15_M07_F10_KA22_13.mat', 'N15_M07_F10_KA22_12.mat', 'N15_M07_F10_KA22_5.mat', 'N15_M07_F10_KA22_4.mat', 'N15_M07_F10_KA22_6.mat', 'N15_M07_F10_KA22_7.mat', 'N15_M07_F10_KA22_3.mat', 'N15_M07_F10_KA22_2.mat', 'N15_M07_F10_KA22_1.mat']\n",
      "Y is:\n",
      "2\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KA30', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KA30.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KA30/raw/KA30.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KA30_5.mat', 'N15_M07_F10_KA30_4.mat', 'N15_M07_F10_KA30_6.mat', 'N15_M07_F10_KA30_20.mat', 'N15_M07_F10_KA30_7.mat', 'N15_M07_F10_KA30_3.mat', 'N15_M07_F10_KA30_19.mat', 'N15_M07_F10_KA30_18.mat', 'N15_M07_F10_KA30_2.mat', 'N15_M07_F10_KA30_1.mat', 'N15_M07_F10_KA30_16.mat', 'N15_M07_F10_KA30_17.mat', 'N15_M07_F10_KA30_15.mat', 'N15_M07_F10_KA30_14.mat', 'N15_M07_F10_KA30_10.mat', 'N15_M07_F10_KA30_11.mat', 'N15_M07_F10_KA30_9.mat', 'N15_M07_F10_KA30_13.mat', 'N15_M07_F10_KA30_12.mat', 'N15_M07_F10_KA30_8.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI01', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI01.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI01/raw/KI01.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI01_18.mat', 'N15_M07_F10_KI01_19.mat', 'N15_M07_F10_KI01_20.mat', 'N15_M07_F10_KI01_8.mat', 'N15_M07_F10_KI01_9.mat', 'N15_M07_F10_KI01_7.mat', 'N15_M07_F10_KI01_6.mat', 'N15_M07_F10_KI01_4.mat', 'N15_M07_F10_KI01_5.mat', 'N15_M07_F10_KI01_1.mat', 'N15_M07_F10_KI01_2.mat', 'N15_M07_F10_KI01_3.mat', 'N15_M07_F10_KI01_11.mat', 'N15_M07_F10_KI01_10.mat', 'N15_M07_F10_KI01_12.mat', 'N15_M07_F10_KI01_13.mat', 'N15_M07_F10_KI01_17.mat', 'N15_M07_F10_KI01_16.mat', 'N15_M07_F10_KI01_14.mat', 'N15_M07_F10_KI01_15.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI03', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI03.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI03/raw/KI03.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI03_20.mat', 'N15_M07_F10_KI03_18.mat', 'N15_M07_F10_KI03_19.mat', 'N15_M07_F10_KI03_9.mat', 'N15_M07_F10_KI03_8.mat', 'N15_M07_F10_KI03_5.mat', 'N15_M07_F10_KI03_4.mat', 'N15_M07_F10_KI03_6.mat', 'N15_M07_F10_KI03_7.mat', 'N15_M07_F10_KI03_3.mat', 'N15_M07_F10_KI03_2.mat', 'N15_M07_F10_KI03_1.mat', 'N15_M07_F10_KI03_14.mat', 'N15_M07_F10_KI03_15.mat', 'N15_M07_F10_KI03_17.mat', 'N15_M07_F10_KI03_16.mat', 'N15_M07_F10_KI03_12.mat', 'N15_M07_F10_KI03_13.mat', 'N15_M07_F10_KI03_11.mat', 'N15_M07_F10_KI03_10.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI04', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI04.rar']]\n",
      "no dir/file\n",
      "Downloading to: './data/PDB/KI04/raw/KI04.rar'\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI04/raw/KI04.rar\n",
      "patool: Extracting ./data/PDB/KI04/raw/KI04.rar ...\n",
      "patool: running /usr/local/bin/unrar x -- /Users/opprud/workspace/ceramicspeed/bearingbrain/tools/dataset_for_test/external_data/4_paderborn/data/PDB/KI04/raw/KI04.rar\n",
      "patool:     with cwd='./data/PDB/KI04'\n",
      "patool: ... ./data/PDB/KI04/raw/KI04.rar extracted to `./data/PDB/KI04'.\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI04_9.mat', 'N15_M07_F10_KI04_14.mat', 'N15_M07_F10_KI04_15.mat', 'N15_M07_F10_KI04_8.mat', 'N15_M07_F10_KI04_17.mat', 'N15_M07_F10_KI04_16.mat', 'N15_M07_F10_KI04_12.mat', 'N15_M07_F10_KI04_13.mat', 'N15_M07_F10_KI04_11.mat', 'N15_M07_F10_KI04_10.mat', 'N15_M07_F10_KI04_20.mat', 'N15_M07_F10_KI04_1.mat', 'N15_M07_F10_KI04_3.mat', 'N15_M07_F10_KI04_2.mat', 'N15_M07_F10_KI04_6.mat', 'N15_M07_F10_KI04_7.mat', 'N15_M07_F10_KI04_5.mat', 'N15_M07_F10_KI04_18.mat', 'N15_M07_F10_KI04_19.mat', 'N15_M07_F10_KI04_4.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI05', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI05.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI05/raw/KI05.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI05_20.mat', 'N15_M07_F10_KI05_9.mat', 'N15_M07_F10_KI05_8.mat', 'N15_M07_F10_KI05_19.mat', 'N15_M07_F10_KI05_18.mat', 'N15_M07_F10_KI05_16.mat', 'N15_M07_F10_KI05_3.mat', 'N15_M07_F10_KI05_2.mat', 'N15_M07_F10_KI05_17.mat', 'N15_M07_F10_KI05_15.mat', 'N15_M07_F10_KI05_1.mat', 'N15_M07_F10_KI05_14.mat', 'N15_M07_F10_KI05_10.mat', 'N15_M07_F10_KI05_5.mat', 'N15_M07_F10_KI05_4.mat', 'N15_M07_F10_KI05_11.mat', 'N15_M07_F10_KI05_13.mat', 'N15_M07_F10_KI05_6.mat', 'N15_M07_F10_KI05_7.mat', 'N15_M07_F10_KI05_12.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI07', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI07.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI07/raw/KI07.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI07_8.mat', 'N15_M07_F10_KI07_9.mat', 'N15_M07_F10_KI07_19.mat', 'N15_M07_F10_KI07_18.mat', 'N15_M07_F10_KI07_20.mat', 'N15_M07_F10_KI07_1.mat', 'N15_M07_F10_KI07_13.mat', 'N15_M07_F10_KI07_12.mat', 'N15_M07_F10_KI07_2.mat', 'N15_M07_F10_KI07_10.mat', 'N15_M07_F10_KI07_11.mat', 'N15_M07_F10_KI07_3.mat', 'N15_M07_F10_KI07_7.mat', 'N15_M07_F10_KI07_15.mat', 'N15_M07_F10_KI07_14.mat', 'N15_M07_F10_KI07_6.mat', 'N15_M07_F10_KI07_4.mat', 'N15_M07_F10_KI07_16.mat', 'N15_M07_F10_KI07_17.mat', 'N15_M07_F10_KI07_5.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI08', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI08.rar']]\n",
      "no dir/file\n",
      "Downloading to: './data/PDB/KI08/raw/KI08.rar'\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI08/raw/KI08.rar\n",
      "patool: Extracting ./data/PDB/KI08/raw/KI08.rar ...\n",
      "patool: running /usr/local/bin/unrar x -- /Users/opprud/workspace/ceramicspeed/bearingbrain/tools/dataset_for_test/external_data/4_paderborn/data/PDB/KI08/raw/KI08.rar\n",
      "patool:     with cwd='./data/PDB/KI08'\n",
      "patool: ... ./data/PDB/KI08/raw/KI08.rar extracted to `./data/PDB/KI08'.\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI08_14.mat', 'N15_M07_F10_KI08_4.mat', 'N15_M07_F10_KI08_5.mat', 'N15_M07_F10_KI08_15.mat', 'N15_M07_F10_KI08_17.mat', 'N15_M07_F10_KI08_7.mat', 'N15_M07_F10_KI08_6.mat', 'N15_M07_F10_KI08_16.mat', 'N15_M07_F10_KI08_12.mat', 'N15_M07_F10_KI08_2.mat', 'N15_M07_F10_KI08_3.mat', 'N15_M07_F10_KI08_13.mat', 'N15_M07_F10_KI08_11.mat', 'N15_M07_F10_KI08_1.mat', 'N15_M07_F10_KI08_10.mat', 'N15_M07_F10_KI08_20.mat', 'N15_M07_F10_KI08_18.mat', 'N15_M07_F10_KI08_8.mat', 'N15_M07_F10_KI08_9.mat', 'N15_M07_F10_KI08_19.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI14', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI14.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI14/raw/KI14.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI14_11.mat', 'N15_M07_F10_KI14_10.mat', 'N15_M07_F10_KI14_12.mat', 'N15_M07_F10_KI14_13.mat', 'N15_M07_F10_KI14_17.mat', 'N15_M07_F10_KI14_16.mat', 'N15_M07_F10_KI14_14.mat', 'N15_M07_F10_KI14_15.mat', 'N15_M07_F10_KI14_2.mat', 'N15_M07_F10_KI14_3.mat', 'N15_M07_F10_KI14_1.mat', 'N15_M07_F10_KI14_4.mat', 'N15_M07_F10_KI14_5.mat', 'N15_M07_F10_KI14_7.mat', 'N15_M07_F10_KI14_6.mat', 'N15_M07_F10_KI14_8.mat', 'N15_M07_F10_KI14_9.mat', 'N15_M07_F10_KI14_18.mat', 'N15_M07_F10_KI14_19.mat', 'N15_M07_F10_KI14_20.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI16', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI16.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI16/raw/KI16.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI16_14.mat', 'N15_M07_F10_KI16_15.mat', 'N15_M07_F10_KI16_17.mat', 'N15_M07_F10_KI16_16.mat', 'N15_M07_F10_KI16_12.mat', 'N15_M07_F10_KI16_13.mat', 'N15_M07_F10_KI16_11.mat', 'N15_M07_F10_KI16_10.mat', 'N15_M07_F10_KI16_1.mat', 'N15_M07_F10_KI16_3.mat', 'N15_M07_F10_KI16_2.mat', 'N15_M07_F10_KI16_6.mat', 'N15_M07_F10_KI16_7.mat', 'N15_M07_F10_KI16_5.mat', 'N15_M07_F10_KI16_4.mat', 'N15_M07_F10_KI16_9.mat', 'N15_M07_F10_KI16_8.mat', 'N15_M07_F10_KI16_20.mat', 'N15_M07_F10_KI16_18.mat', 'N15_M07_F10_KI16_19.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI17', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI17.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI17/raw/KI17.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI17_3.mat', 'N15_M07_F10_KI17_2.mat', 'N15_M07_F10_KI17_1.mat', 'N15_M07_F10_KI17_5.mat', 'N15_M07_F10_KI17_4.mat', 'N15_M07_F10_KI17_6.mat', 'N15_M07_F10_KI17_7.mat', 'N15_M07_F10_KI17_20.mat', 'N15_M07_F10_KI17_19.mat', 'N15_M07_F10_KI17_18.mat', 'N15_M07_F10_KI17_16.mat', 'N15_M07_F10_KI17_17.mat', 'N15_M07_F10_KI17_15.mat', 'N15_M07_F10_KI17_14.mat', 'N15_M07_F10_KI17_10.mat', 'N15_M07_F10_KI17_11.mat', 'N15_M07_F10_KI17_13.mat', 'N15_M07_F10_KI17_12.mat', 'N15_M07_F10_KI17_9.mat', 'N15_M07_F10_KI17_8.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI18', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI18.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI18/raw/KI18.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI18_11.mat', 'N15_M07_F10_KI18_10.mat', 'N15_M07_F10_KI18_12.mat', 'N15_M07_F10_KI18_13.mat', 'N15_M07_F10_KI18_17.mat', 'N15_M07_F10_KI18_16.mat', 'N15_M07_F10_KI18_14.mat', 'N15_M07_F10_KI18_15.mat', 'N15_M07_F10_KI18_9.mat', 'N15_M07_F10_KI18_8.mat', 'N15_M07_F10_KI18_6.mat', 'N15_M07_F10_KI18_7.mat', 'N15_M07_F10_KI18_5.mat', 'N15_M07_F10_KI18_4.mat', 'N15_M07_F10_KI18_1.mat', 'N15_M07_F10_KI18_3.mat', 'N15_M07_F10_KI18_2.mat', 'N15_M07_F10_KI18_18.mat', 'N15_M07_F10_KI18_19.mat', 'N15_M07_F10_KI18_20.mat']\n",
      "Y is:\n",
      "3\n",
      "filestring\n",
      "N15_M07_F10_\n",
      "l: \n",
      "[['KI21', '1500', '400', 'http://groups.uni-paderborn.de/kat/BearingDataCenter/KI21.rar']]\n",
      "file to exrtract is is::\n",
      "./data/PDB/KI21/raw/KI21.rar\n",
      "file already extracted, skipping unrar\n",
      "sorted filelist:\n",
      "['N15_M07_F10_KI21_8.mat', 'N15_M07_F10_KI21_20.mat', 'N15_M07_F10_KI21_9.mat', 'N15_M07_F10_KI21_18.mat', 'N15_M07_F10_KI21_19.mat', 'N15_M07_F10_KI21_2.mat', 'N15_M07_F10_KI21_17.mat', 'N15_M07_F10_KI21_16.mat', 'N15_M07_F10_KI21_3.mat', 'N15_M07_F10_KI21_1.mat', 'N15_M07_F10_KI21_14.mat', 'N15_M07_F10_KI21_15.mat', 'N15_M07_F10_KI21_4.mat', 'N15_M07_F10_KI21_11.mat', 'N15_M07_F10_KI21_10.mat', 'N15_M07_F10_KI21_5.mat', 'N15_M07_F10_KI21_7.mat', 'N15_M07_F10_KI21_12.mat', 'N15_M07_F10_KI21_13.mat', 'N15_M07_F10_KI21_6.mat']\n"
     ]
    }
   ],
   "source": [
    "fsAcc = 64000      # samples /sec\n",
    "sampLen = 3*fsAcc  # 3 sec.\n",
    "\n",
    "be_data = []\n",
    "\n",
    "#healthy sets\n",
    "be_data.append(PDB('K001','1500','1000','700',sampLen))\n",
    "be_data.append(PDB('K002','1500','1000','700',sampLen))\n",
    "be_data.append(PDB('K003','1500','1000','700',sampLen))\n",
    "be_data.append(PDB('K004','1500','1000','700',sampLen))\n",
    "be_data.append(PDB('K005','1500','1000','700',sampLen))\n",
    "be_data.append(PDB('K006','1500','1000','700',sampLen))\n",
    "\n",
    "#outerring\n",
    "be_data.append(PDB('KA01','1500','1000','700',sampLen)) #EDM\n",
    "be_data.append(PDB('KA03','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA04','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA05','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA06','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA07','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA08','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA09','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA15','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA16','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA22','1500','1000','700',sampLen)) #\n",
    "be_data.append(PDB('KA30','1500','1000','700',sampLen)) #\n",
    "\n",
    "#innerring\n",
    "be_data.append(PDB('KI01','1500','1000','700',sampLen)) #EDM   severity: 1\n",
    "be_data.append(PDB('KI03','1500','1000','700',sampLen)) #Elec  severity: 1\n",
    "be_data.append(PDB('KI04','1500','1000','700',sampLen)) #HALT  severity: 1\n",
    "be_data.append(PDB('KI05','1500','1000','700',sampLen)) #Elec  severity: 1\n",
    "be_data.append(PDB('KI07','1500','1000','700',sampLen)) #Elec  severity: 2\n",
    "be_data.append(PDB('KI08','1500','1000','700',sampLen)) #Elec  severity: 2\n",
    "be_data.append(PDB('KI14','1500','1000','700',sampLen)) #HALT  severity: 1\n",
    "be_data.append(PDB('KI16','1500','1000','700',sampLen)) #HALT  severity: 3\n",
    "be_data.append(PDB('KI17','1500','1000','700',sampLen)) #HALT  severity: 1\n",
    "be_data.append(PDB('KI18','1500','1000','700',sampLen)) #HALT  severity: 2\n",
    "be_data.append(PDB('KI21','1500','1000','700',sampLen)) #HALT  severity: 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## play sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(be_data)#[0].X_train[0])\n",
    "#be_data[0].y_label\n",
    "#dict_labels[1]\n",
    "\n",
    "np.shape(be_data[5].X_train)\n",
    "\n",
    "len(be_data[4].X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/opprud/workspace/ceramicspeed/bearingbrain/tools/dataset_for_test/external_data/4_paderborn\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from serial port and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import csv\n",
    "import struct\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "from numpy import asarray\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "dataFolder = './collected_data/raw/'\n",
    "normalisedDataFolder = './collected_data/normalised/'\n",
    "\n",
    "\"\"\"\n",
    "Read data from connected Apollo3 device and save as waw file\n",
    "\"\"\"\n",
    "def serialPdmToWaw(ser, rxLen, samplerate, filename, scale=True):\n",
    "    # open serial port\n",
    "    ser = serial.Serial(ser,baudrate=115200,timeout=5)\n",
    "    #ser = serial.Serial(ser,baudrate=500000,timeout=5)\n",
    "    ser.flushInput()\n",
    "\n",
    "    # required delay since DTR is pulled when port opens, this resets the CPU through the bootload circuit\n",
    "    time.sleep(1.0)\n",
    "    # write any char to CPU to start samopling\n",
    "    ser.write(b'\\n')\n",
    "    \n",
    "    # capture incoming data, \n",
    "    # Sampling starts by simpy resetting the Artemis Nano board\n",
    "    ser_bytes = ser.read(size=rxLen)\n",
    "    print(\"got %d\",len(ser_bytes))\n",
    "\n",
    "    L = int(len(ser_bytes))\n",
    "    l2 = int(L/2)\n",
    "    \n",
    "    # unpack data into array\n",
    "    DATA = struct.unpack('%dh'%l2,ser_bytes)\n",
    "    d = asarray(DATA)    \n",
    "    \n",
    "    #set sample rate\n",
    "    samplerate = fs #46875;\n",
    "    \n",
    "    # multiply to max range for a 16 bit vaw\n",
    "    if(scale == True):\n",
    "        B15_MAX = (1 << 15) - 1\n",
    "        mul = B15_MAX / d.max()\n",
    "        d_norm = d*(mul/2)\n",
    "        # if file already exists, avoid duplicate downloads\n",
    "        if not os.path.exists(normalisedDataFolder):\n",
    "            os.makedirs(normalisedDataFolder)\n",
    "            print(\"creating raw data dir\")\n",
    "        # write file\n",
    "        write(normalisedDataFolder+filename+\"_norm.wav\", samplerate, d_norm)   \n",
    "\n",
    "    if not os.path.exists(dataFolder):\n",
    "        os.makedirs(dataFolder)\n",
    "        print(\"creating data dir\")\n",
    "\n",
    "    # write filename\n",
    "    write(dataFolder+filename+\"_raw.wav\", samplerate, d)   \n",
    "\n",
    "    #close port\n",
    "    ser.close()\n",
    "\n",
    "    return ser\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "got %d 40000\n",
      "OK\n",
      "got %d 40000\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import time\n",
    "fs_playback=64000\n",
    "\n",
    "port = '/dev/cu.wchusbserial1430' \n",
    "#141320'\n",
    "fs   = 15625 #using arduino waw example settings\n",
    "        #46875   #hardcoded in CPU \n",
    "l    = 40000#24000\n",
    "#fn   = \"s600_2\"\n",
    "\n",
    "#ser = serialPdmToWaw(port, l, fs, fn, True)\n",
    "\n",
    "dict_labels = {1 :'OK', 2: 'OUTER', 3 : 'INNER', 4 : 'BOTH'}\n",
    "\n",
    "for i in range(2):#2np.shape(be_data)[0]):\n",
    "    # any data ?\n",
    "    if(len(be_data[i].X_train) > 0):\n",
    "        s = be_data[i].X_train[0]\n",
    "        #sd.play(s,samplerate=fs_playback)\n",
    "        print(dict_labels[be_data[i].y_label])\n",
    "        #capture data and store\n",
    "        filename = ( str(dict_labels[be_data[i].y_label])+'_test3_'+str(i))\n",
    "        ser = serialPdmToWaw(port, l, fs, filename, True)\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        print(\"skipping :\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(be_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outerring\n",
    "d_OR_test_1  = PDB('KA22','1500','1000','700',SliceLen) \n",
    "d_OR_train_2 = PDB('KA01','1500','1000','700',SliceLen) #EDM\n",
    "d_OR_test_2  = PDB('K004','1500','1000','700',SliceLen)\n",
    "d_OR_train_3 = PDB('KA05','1500','1000','700',SliceLen) #Elec engraved\n",
    "d_OR_test_3  = PDB('KA15','1500','1000','700',SliceLen)\n",
    "d_OR_train_4 = PDB('KA07','1500','1000','700',SliceLen) #Drilling\n",
    "d_OR_test_4  = PDB('KA30','1500','1000','700',SliceLen)\n",
    "d_OR_test_5  = PDB('KA16','1500','1000','700',SliceLen) \n",
    "\n",
    "#innerring\n",
    "d_IR_test_1  = PDB('KI14','1500','1000','700',SliceLen)\n",
    "d_IR_train_2 = PDB('KI01','1500','1000','700',SliceLen) #EDM\n",
    "d_IR_test_2  = PDB('KI21','1500','1000','700',SliceLen)\n",
    "d_IR_train_3 = PDB('KI05','1500','1000','700',SliceLen) #Elct engraved\n",
    "d_IR_test_3  = PDB('KI17','1500','1000','700',SliceLen)\n",
    "d_IR_train_4 = PDB('KI07','1500','1000','700',SliceLen) #Elec engraved\n",
    "d_IR_test_4  = PDB('KI18','1500','1000','700',SliceLen)\n",
    "d_IR_test_5  = PDB('KI16','1500','1000','700',SliceLen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 192000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ok1.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(be_data[0].y_label)\n",
    "be_data[5].y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ok_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
